{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299cee3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "deepchem.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49edc77",
   "metadata": {},
   "source": [
    "En los tutoriales hasta ahora, hemos seguido un procedimiento simple para entrenar modelos: cargar un conjunto de datos, crear un modelo, llamar a `fit()`, evaluarlo y dar por terminado el proceso. Eso está bien para un ejemplo, pero en proyectos reales de aprendizaje automático, el proceso suele ser más complicado. En este tutorial, examinaremos un flujo de trabajo más realista para entrenar un modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2f836",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fb671",
   "metadata": {},
   "source": [
    "Emprezaremos cargando el HIV dataset. Clasifica 40000 molécula en función de si inhiben o no la replicación HIV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c176331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'split' is deprecated.  Use 'splitter' instead.\n",
      "[10:04:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:04:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:04:37] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:04:37] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_hiv(featurizer='ECFP', split='scaffold')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ecb3a9",
   "metadata": {},
   "source": [
    "Ahora, vamos a entrenar un modelo en estos datos. Utilizaremos un `MultitaskClassifier`, que es simplemente una pila de capas densas. Sin embargo, esto todavía deja muchas opciones abiertas. ¿Cuántas capas debería haber y qué ancho debería tener cada una? ¿Qué tasa de eliminación (dropout) debemos usar? ¿Qué tasa de aprendizaje?\n",
    "\n",
    "Estos se llaman hiperparámetros. La forma estándar de seleccionarlos es probar muchas combinaciones de valores, entrenar cada modelo en el conjunto de entrenamiento y evaluarlo en el conjunto de validación. Esto nos permite ver cuáles funcionan mejor.\n",
    "\n",
    "Puedes hacerlo manualmente, pero generalmente es más fácil dejar que la computadora lo haga por ti. **DeepChem proporciona una selección de algoritmos de optimización de hiperparámetros, que se encuentran en el paquete `dc.hyper`**. Para este ejemplo, utilizaremos `GridHyperparamOpt`, que es el método más básico. Simplemente le proporcionamos una lista de opciones para cada hiperparámetro y probará exhaustivamente todas las combinaciones de ellos.\n",
    "\n",
    "Las listas de opciones se definen mediante un diccionario que proporcionamos. Para cada uno de los argumentos del modelo, proporcionamos una lista de valores para probar. En este ejemplo, consideramos tres posibles conjuntos de capas ocultas: una sola capa de ancho 500, una sola capa de ancho 1000 o dos capas, cada una de ancho 1000. También consideramos dos tasas de eliminación (dropout) (20% y 50%) y dos tasas de aprendizaje (0.001 y 0.0001).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4356cf4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7536/2460524673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Definimos la métrica de evaluación (ROC)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m best_model, best_hyperparams, all_results = optimizer.hyperparam_search(\n\u001b[0m\u001b[0;32m     12\u001b[0m         params_dict, train_dataset, valid_dataset, metric, transformers)\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\hyper\\grid_search.py\u001b[0m in \u001b[0;36mhyperparam_search\u001b[1;34m(self, params_dict, train_dataset, valid_dataset, metric, output_transformers, nb_epoch, use_max, logfile, logdir, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m       \u001b[1;31m# mypy test throws error, so ignoring it in try\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m       \u001b[1;31m# Not all models have nb_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\torch_models\\torch_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m    \"\"\"\n\u001b[1;32m--> 330\u001b[1;33m     return self.fit_generator(\n\u001b[0m\u001b[0;32m    331\u001b[0m         self.default_generator(dataset,\n\u001b[0;32m    332\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\torch_models\\torch_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\fcnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    133\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mnext_activation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m           \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_dict = {\n",
    "    'n_tasks': [len(tasks)],\n",
    "    'n_features': [1024],\n",
    "    #una sola capa de ancho 500, una sola capa de ancho 1000 o dos capas, cada una de ancho 1000. \n",
    "    'layer_sizes': [[500], [1000], [1000, 1000]]\n",
    "}\n",
    "#Definimos el optimizador que esta dentro de dc.hyper usando GridHyperparamOpt y dentro le indicamos el modelo\n",
    "optimizer = dc.hyper.GridHyperparamOpt(dc.models.MultitaskClassifier)\n",
    "#Definimos la métrica de evaluación (ROC)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
    "        params_dict, train_dataset, valid_dataset, metric, transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb87a0",
   "metadata": {},
   "source": [
    "**`hyperparam_search()` devuelve tres argumentos: el mejor modelo que encontró, los hiperparámetros para ese modelo y una lista completa de la puntuación de validación para cada modelo.** Echemos un vistazo al último.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e317d65c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7536/3056958119.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1bbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8accd5dd",
   "metadata": {},
   "source": [
    "Podemos observar algunos patrones generales. El uso de dos capas con una tasa de aprendizaje más alta no funciona muy bien. Parece que el modelo más profundo requiere una tasa de aprendizaje más pequeña. También vemos que el dropout del 20% generalmente funciona mejor que el del 50%. Una vez que reducimos la lista de modelos en función de estas observaciones, todas las puntuaciones de validación son muy similares entre sí, probablemente lo suficientemente cercanas como para que la variación restante sea principalmente ruido. No parece marcar una gran diferencia cuál de los conjuntos de hiperparámetros restantes usemos, así que elijamos arbitrariamente una sola capa de ancho 1000 y una tasa de aprendizaje de 0.0001.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844b5ab",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3070469",
   "metadata": {},
   "source": [
    "Existe otro hiperparámetro importante que aún no hemos considerado: cuánto tiempo entrenamos el modelo. `GridHyperparamOpt` entrena cada modelo durante un número fijo de épocas bastante pequeño. Ese número no siempre es el mejor.\n",
    "\n",
    "Podrías esperar que cuanto más tiempo entrenes, mejor será tu modelo, pero eso no suele ser cierto. Si entrenas durante demasiado tiempo, el modelo generalmente comenzará a ajustarse demasiado a detalles irrelevantes del conjunto de entrenamiento. Puedes darte cuenta de que esto está ocurriendo cuando la puntuación en el conjunto de validación deja de aumentar e incluso puede disminuir, mientras que la puntuación en el conjunto de entrenamiento continúa mejorando.\n",
    "\n",
    "Afortunadamente, no necesitamos entrenar muchos modelos diferentes durante diferentes números de pasos para identificar el número óptimo. Simplemente lo entrenamos una vez, monitoreamos la puntuación en el conjunto de validación y mantenemos los parámetros que la maximizan. Esto se llama \"detención temprana\" (early stopping). La clase ValidationCallback de DeepChem puede hacer esto automáticamente por nosotros. En el ejemplo a continuación, le pedimos que calcule el área bajo la curva ROC (ROC AUC) en el conjunto de validación cada 1000 pasos de entrenamiento. Si agregas el argumento save_dir, también guardará una copia de los mejores parámetros del modelo en el disco.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "643b6864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.74626\n",
      "Step 2000 validation: roc_auc_score=0.777488\n",
      "Step 3000 validation: roc_auc_score=0.764931\n",
      "Step 4000 validation: roc_auc_score=0.76371\n",
      "Step 5000 validation: roc_auc_score=0.765363\n",
      "Step 6000 validation: roc_auc_score=0.769145\n",
      "Step 7000 validation: roc_auc_score=0.771971\n",
      "Step 8000 validation: roc_auc_score=0.76969\n",
      "Step 9000 validation: roc_auc_score=0.75637\n",
      "Step 10000 validation: roc_auc_score=0.762185\n",
      "Step 11000 validation: roc_auc_score=0.762369\n",
      "Step 12000 validation: roc_auc_score=0.766334\n",
      "Step 13000 validation: roc_auc_score=0.767072\n",
      "Step 14000 validation: roc_auc_score=0.768024\n",
      "Step 15000 validation: roc_auc_score=0.763817\n",
      "Step 16000 validation: roc_auc_score=0.765382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6580063629150391"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dc.models.MultitaskClassifier(n_tasks=len(tasks),\n",
    "                                      n_features=1024,\n",
    "                                      layer_sizes=[1000],\n",
    "                                      dropouts=0.2,\n",
    "                                      learning_rate=0.0001)\n",
    "#Especificamos un callback que nos vaya avisando cada 1000 pasos la métrica\n",
    "metric = [dc.metrics.Metric(dc.metrics.roc_auc_score)]\n",
    "callback = dc.models.ValidationCallback(valid_dataset, 1000, metric)\n",
    "model.fit(train_dataset, nb_epoch=50, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358e90b",
   "metadata": {},
   "source": [
    "## Learning Rate Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddb01c",
   "metadata": {},
   "source": [
    "En los ejemplos anteriores, utilizamos una tasa de aprendizaje fija durante todo el entrenamiento. En algunos casos, funciona mejor variar la tasa de aprendizaje durante el entrenamiento. Para hacer esto en DeepChem, simplemente especificamos un objeto LearningRateSchedule en lugar de un número para el argumento `learning_rate`. En el siguiente ejemplo, utilizamos una tasa de aprendizaje que disminuye de manera exponencial. Comienza en 0.0002 y luego se multiplica por 0.9 después de cada 1000 pasos.\n",
    "\n",
    "**NOTA: Una tasa de aprendizaje (Learning_rate) representa la magnitud con la que los parámetros del modelo se actualizan durante el proceso de entrenamiento. En esencia, es un valor que determina cuánto deben cambiar los pesos del modelo en respuesta a los errores calculados durante el entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bcdd5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 validation: roc_auc_score=0.750672\n",
      "Step 2000 validation: roc_auc_score=0.774874\n",
      "Step 3000 validation: roc_auc_score=0.764491\n",
      "Step 4000 validation: roc_auc_score=0.772914\n",
      "Step 5000 validation: roc_auc_score=0.769999\n",
      "Step 6000 validation: roc_auc_score=0.762317\n",
      "Step 7000 validation: roc_auc_score=0.770688\n",
      "Step 8000 validation: roc_auc_score=0.770244\n",
      "Step 9000 validation: roc_auc_score=0.767291\n",
      "Step 10000 validation: roc_auc_score=0.76709\n",
      "Step 11000 validation: roc_auc_score=0.765186\n",
      "Step 12000 validation: roc_auc_score=0.769038\n",
      "Step 13000 validation: roc_auc_score=0.768695\n",
      "Step 14000 validation: roc_auc_score=0.770725\n",
      "Step 15000 validation: roc_auc_score=0.770621\n",
      "Step 16000 validation: roc_auc_score=0.771401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4875274658203125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Utilizamos una tasa de aprendizaje que disminuye de manera exponencial. Comienza en 0.0002 \n",
    "y luego se multiplica por 0.9 después de cada 1000 pasos.\n",
    "'''\n",
    "learning_rate = dc.models.optimizers.ExponentialDecay(0.0002, 0.9, 1000)\n",
    "model = dc.models.MultitaskClassifier(n_tasks=len(tasks),\n",
    "                                      n_features=1024,\n",
    "                                      layer_sizes=[1000],\n",
    "                                      dropouts=0.2,\n",
    "                                      learning_rate=learning_rate)\n",
    "model.fit(train_dataset, nb_epoch=50, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21d01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
