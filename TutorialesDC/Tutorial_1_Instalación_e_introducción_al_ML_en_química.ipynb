{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea53b9ca",
   "metadata": {},
   "source": [
    "# Tutorial 1: Instalación e introducción al ML en química"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babebfe",
   "metadata": {},
   "source": [
    "### Instalación de la librería DeepChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff63586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\alloh\\miniconda3\\lib\\site-packages (3.10.0.2)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "Successfully installed typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d3f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem[tensorflow] in c:\\users\\alloh\\miniconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (1.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (1.2.0)\n",
      "Requirement already satisfied: scipy<1.9 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (1.21.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (1.3.5)\n",
      "Requirement already satisfied: rdkit in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (2023.3.2)\n",
      "Requirement already satisfied: tensorflow-addons in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (0.21.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-probability in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from deepchem[tensorflow]) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from pandas->deepchem[tensorflow]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from pandas->deepchem[tensorflow]) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->deepchem[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from rdkit->deepchem[tensorflow]) (8.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from scikit-learn->deepchem[tensorflow]) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow->deepchem[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.28.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (22.12.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.13.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.51.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (58.0.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.4.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (4.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (1.26.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow->deepchem[tensorflow]) (3.0.4)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-addons->deepchem[tensorflow]) (2.13.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-probability->deepchem[tensorflow]) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-probability->deepchem[tensorflow]) (0.1.8)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\alloh\\miniconda3\\lib\\site-packages (from tensorflow-probability->deepchem[tensorflow]) (2.0.0)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.8.0\n",
      "    Uninstalling typing-extensions-4.8.0:\n",
      "      Successfully uninstalled typing-extensions-4.8.0\n",
      "Successfully installed typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre deepchem[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e828120f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/4048313604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetalearning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\hyper\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_classes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperparamOpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridHyperparamOpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_process\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianProcessHyperparamOpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_search\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomHyperparamOpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\hyper\\base_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrans\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# PyTorch models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTorchModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAttentiveFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttentiveFPModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCGCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCGCNNModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTorchModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattentivefp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAttentiveFP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttentiveFPModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorch_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcgcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCGCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCGCNNModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\deepchem\\models\\torch_models\\torch_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0m_has_tensorboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mraise\u001b[0m  \u001b[1;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Base'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef294e",
   "metadata": {},
   "source": [
    "**Pasos básicos para el entrenamiento de un modelo**\n",
    "- Selección del dataset de entrenamiento de nuestro modelo \n",
    "- Creación del modelo \n",
    "- Entrenamiento del modelo\n",
    "- Evaluación del modelo en un conjunto de datos específicos para las pruebas\n",
    "- Hacer predicciones sobre nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1623ff8",
   "metadata": {},
   "source": [
    "## Paso 1. Selección del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4f662",
   "metadata": {},
   "source": [
    "El primer problema al que nos enfrentaremos y buscaremos solucionar con DeepChem es el de **predecir la solubilidad de pequeñas moléculas dada su fórmula química.** Esto es una propiedad importante en el desarrollo de fármacos, ya que si el fármaco propuesto **no es lo suficientemente soluble, probablemente no llegue hasta el torrente sanguineo para tener un efecto terapeutico.**\n",
    "\n",
    "Lo primero que necesitamos es un **dataset de medidas de solubilidades para moléculas reales.** Uno de los componentes principales de DeepChem es **MoleculeNet**, una **colección de quimica y molecular datasets.** Para ello, usaremos la **Delaney solubility dataset.** La propiedad de solubilidad en este dataset esta establecida como **log(solubility)** donde la solubilidad esta medida en **moles/litro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53354e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#De la librería DeepChem cargamos el dataset delaney. En el argumento \n",
    "#Featurizer indicaremos la representación que queremos usar para las\n",
    "#moléculas. En este caso, hemos indicado Grafos. La manera en la que es\n",
    "#representada los datos es conocida como Featurize.\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "#Del dataset que hemos cargado vamos a separarlo en un dataset de\n",
    "#entrenamiento, otro de validación y otro de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07e574",
   "metadata": {},
   "source": [
    "Podemos observar que del dataset que hemos cargado lo separamos en tres conjuntos, uno de entrenamiento, otro de validación y otro de pruebas.\n",
    "* **Conjunto de Entrenamiento (train_dataset):**\n",
    "  * Este conjunto se utiliza para entrenar el modelo. Contiene ejemplos de datos etiquetados (entradas y las respuestas correctas).\n",
    "  * El modelo aprende de estos datos y ajusta sus parámetros durante el proceso de entrenamiento para hacer predicciones precisas.\n",
    "  * Por lo general, el conjunto de entrenamiento es el más grande, ya que se necesita una cantidad significativa de datos para entrenar un modelo de manera efectiva.\n",
    "* **Conjunto de Entrenamiento (train_dataset):**\n",
    "  * Este conjunto se utiliza para ajustar hiperparámetros del modelo y evaluar su rendimiento durante el entrenamiento.\n",
    "  * Se utiliza para comprobar si el modelo está sobreajustando (overfitting) los datos de entrenamiento.\n",
    "  * Los hiperparámetros (como la tasa de aprendizaje) se ajustan utilizando este conjunto para optimizar el rendimiento del modelo.\n",
    "\n",
    "* **Conjunto de Prueba (test_dataset):**\n",
    "    * Este conjunto se utiliza para evaluar el rendimiento final del modelo después de que se ha entrenado y ajustado con el conjunto de entrenamiento y el conjunto de validación.\n",
    "    * Los datos de prueba son completamente independientes de los datos de entrenamiento y validación, lo que permite evaluar la capacidad del modelo para generalizar a nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c79ffc",
   "metadata": {},
   "source": [
    "## Paso 2. Creación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f8073",
   "metadata": {},
   "source": [
    "Una vez que tenemos los datos listos procedemos a crear el modelo. Usaremos un modelo llamado \"graph convolutional network\" o \"graphcov\". Este es un modelo para procesar datos estructurados o gráficos, como moléculas o proteínas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b81cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e54a0",
   "metadata": {},
   "source": [
    "Los distintos valores de entrada al parámetro significan lo siguiente:\n",
    "\n",
    "* **dc.models.GraphConvModel:** Esto crea un objeto de modelo de tipo GraphConvModel de DeepChem. GraphConvModel es un modelo diseñado para procesar datos estructurados o gráficos, como moléculas en química o proteínas en biología.\n",
    "\n",
    "* **n_tasks=1:** Este parámetro especifica el número de tareas o salidas que se esperan del modelo. En este caso, se configura en 1, lo que sugiere que el modelo se está entrenando para una tarea específica. Si se tratara de una tarea de clasificación con varias clases, este número sería mayor.\n",
    "\n",
    "* **mode='regression':** El modo de operación del modelo se establece en \"regression\", lo que indica que se está configurando el modelo para realizar una tarea de regresión. En una tarea de regresión, el modelo predice valores numéricos continuos en lugar de etiquetas categóricas.\n",
    "\n",
    "* **dropout=0.2:** El valor 0.2 se refiere a la tasa de dropout, que es una técnica de regularización utilizada en redes neuronales. Un valor de 0.2 significa que durante el entrenamiento, el 20% de las conexiones en la red se desactivarán aleatoriamente en cada paso de entrenamiento para prevenir el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd5ba2",
   "metadata": {},
   "source": [
    "## Paso 3. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10129a3c",
   "metadata": {},
   "source": [
    "Una vez generado el modelo el siguiente paso es entrenarlo. Para ello, haremos uso de fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84eee848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11181475639343262"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=100) #Entrenamos el modelo usando el\n",
    "                                       #conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e056abd",
   "metadata": {},
   "source": [
    "El argumento **nb_epoch=100** indica que el modelo se entrenará durante 100 épocas. Durante cada una de estas 100 épocas, el modelo procesará todo el conjunto de datos de entrenamiento train_dataset para aprender a realizar predicciones más precisas.\n",
    "\n",
    "El uso de múltiples épocas es común en el entrenamiento de modelos de aprendizaje automático para asegurar que el modelo haya tenido la oportunidad de aprender de manera efectiva a partir de los datos. Sin embargo, la cantidad óptima de épocas puede variar según el problema y el modelo, por lo que a menudo se realiza ajuste fino de este valor para lograr un equilibrio entre un entrenamiento efectivo y la prevención del sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4d32b",
   "metadata": {},
   "source": [
    "## Paso 4. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b62e60",
   "metadata": {},
   "source": [
    "El siguiente paso tras entrenar el modelo es evaluarlo. Para ello, evaluaremos el modelo tanto para el conjunto de entrenamiento como para el conjunto de pruebas. Para ello, estableceremos la métrica de la correlación de Pearson, es decir, r^2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800bc3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'pearson_r2_score': 0.9176339136802922}\n",
      "Test set score: {'pearson_r2_score': 0.6172329850299577}\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b0281",
   "metadata": {},
   "source": [
    "Vemos que tenemos muy buen rendimiento en el conjunto de entrenamiento pero algo malo en el conjunto de pruebas. Esto es lo que se le conoce como sobreajuste u overfitting.\n",
    "\n",
    "Aún así, nuestra métrica no esta mal. Un modelo que produjese predicciones aleatorias tendria una correlación de 0, mientras que una que hiciese predicciones perfectas tendria correlación de 1. Nuestro modelo no lo hace tan mal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0eee9",
   "metadata": {},
   "source": [
    "## Paso 5. Predicciones con nuevas moléculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd48a18",
   "metadata": {},
   "source": [
    "Haremos predicciones de las primeras diez moléculas del conjunto de pruebas. Para cada una de ellas, imprimiremos su estructura química (SMILES string) y la solubilidad que ha predecido (log(solubility)). Tambien mostraremos la solubilidad real dentro del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a36abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.645381] [-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34\n",
      "[1.0510993] [0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1\n",
      "[-0.47844103] [-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
      "[-2.1627705] [-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
      "[-1.4858996] [-0.52891635] C1=Cc2cccc3cccc1c23\n",
      "[1.7102858] [1.10168349] CC1CO1\n",
      "[-0.52068216] [-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
      "[-0.7695658] [-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
      "[-1.2130748] [-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
      "[0.84965193] [-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n"
     ]
    }
   ],
   "source": [
    "#Realizamos las predicciones con nuestro modelo.\n",
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "\n",
    "#Recorremos las tres listas simultaneamente e imprimimos el SMILES de la\n",
    "#molécula, la predicción de la solubilidad y la solubilidad real.\n",
    "for molecule, solubility, test_solubility in zip(test_dataset.ids, solubilities, test_dataset.y):\n",
    "    print(solubility, test_solubility, molecule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
